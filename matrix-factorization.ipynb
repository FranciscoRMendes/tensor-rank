{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T18:46:28.917139100Z",
     "start_time": "2024-04-05T18:46:28.901647900Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbdddfb-9c40-4d7c-9869-24c477474401",
   "metadata": {},
   "source": [
    "# Basic set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ddfd4c094570c65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T18:46:31.958064600Z",
     "start_time": "2024-04-05T18:46:31.931021900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.int64)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.int64)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864919b-598d-4742-bd8c-4e619ef74180",
   "metadata": {},
   "source": [
    "# Define a basic neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a180e3cde0d75f89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T18:46:33.144477800Z",
     "start_time": "2024-04-05T18:46:33.096947Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# # regular model \n",
    "def set_seed(seed_value):\n",
    "    \"\"\"Set seed for reproducibility\"\"\"\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)  # if you are using CUDA\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    np.random.seed(seed_value)\n",
    "    random.seed(seed_value)\n",
    "\n",
    "# Set a seed value\n",
    "seed = 42\n",
    "set_seed(seed)\n",
    "\n",
    "# # # Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 10)  # 4 input features, 10 neurons in the hidden layer\n",
    "        self.fc2 = nn.Linear(10, 3)  # 10 neurons in the hidden layer, 3 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx == 0:\n",
    "            return self.fc1\n",
    "        elif idx == 1:\n",
    "            return self.fc2\n",
    "        else:\n",
    "            raise IndexError(\"Index out of range\")\n",
    "\n",
    "    def get_first_layer(self):\n",
    "        return self.fc1\n",
    "\n",
    "# define the neural network \n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c8cf96-7bf3-4c46-95cf-72de00514938",
   "metadata": {},
   "source": [
    "# Define a generic training routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c2ab5a9-ac89-49ad-80b7-01dbb8d3b323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(net):\n",
    "    # Define loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.1)\n",
    "    # Train the network\n",
    "    num_epochs = 1000\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()  # zero the gradients\n",
    "        outputs = net(X_train_tensor)  # forward pass\n",
    "        loss = criterion(outputs, y_train_tensor)  # compute the loss\n",
    "        loss.backward()  # backward pass\n",
    "        optimizer.step()  # update weights\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            # print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "            pass\n",
    "    # Test the network\n",
    "    with torch.no_grad():\n",
    "        outputs = net(X_test_tensor)\n",
    "        predicted = torch.argmax(outputs, 1)\n",
    "        accuracy = (predicted == y_test_tensor).sum().item() / y_test_tensor.size(0)\n",
    "        print(f'Accuracy on the test set: {100 * accuracy:.2f}%')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56512200-0d26-4c03-8835-e6a015fbe685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# for benchmarking purposes, lets look at the original accuracy\n",
    "train_nn(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31108af9-f2fe-4755-9168-a8ec297be3da",
   "metadata": {},
   "source": [
    "# Low Rank Approximation of the weight matrix directly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f91310f-9f36-44f2-b261-2b13bb4af290",
   "metadata": {},
   "source": [
    "Extract the first layer weights, find a low tank approximation for them,  $$W^{(1)} \\approx (U_r\\Sigma_r V_r^T)$$. Check that they look similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1b27c4c-03d7-4781-b096-7be29d6f54ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original weights of the first layer:\n",
      "tensor([[-4.1648e-02, -4.6252e-01,  1.7128e+00,  1.5548e+00],\n",
      "        [-4.0338e-02, -1.7054e-01,  7.0191e-01,  6.2048e-01],\n",
      "        [ 1.1626e-01, -6.6152e-01,  9.7242e-01,  1.0223e+00],\n",
      "        [ 1.6039e-01,  2.3432e-01, -1.0579e+00, -8.7162e-01],\n",
      "        [ 2.7400e-01,  2.0377e-01, -1.2229e+00, -9.7948e-01],\n",
      "        [-7.3428e-02,  4.9181e-02, -1.7385e-01, -1.7795e-01],\n",
      "        [-2.8788e-01,  6.2951e-01, -1.1089e+00, -1.1594e+00],\n",
      "        [ 1.2932e-01, -1.9027e-01,  1.5801e-01,  1.9960e-01],\n",
      "        [-2.2499e-02, -1.1339e-01,  4.5061e-01,  4.0080e-01],\n",
      "        [ 2.7131e-04, -7.5118e-04,  1.5493e-03,  1.6636e-03]])\n",
      "\n",
      "Low-rank approximation of the first layer:\n",
      "tensor([[-8.5978e-02, -5.1320e-01,  1.7142e+00,  1.5338e+00],\n",
      "        [-5.5634e-02, -1.8698e-01,  7.0093e-01,  6.1522e-01],\n",
      "        [ 2.0243e-01, -5.7831e-01,  9.9132e-01,  1.0339e+00],\n",
      "        [ 1.4468e-01,  2.1212e-01, -1.0514e+00, -8.8720e-01],\n",
      "        [ 2.4014e-01,  1.6710e-01, -1.2247e+00, -9.9166e-01],\n",
      "        [-2.9847e-02,  9.2167e-02, -1.6558e-01, -1.7037e-01],\n",
      "        [-2.4760e-01,  6.6634e-01, -1.0971e+00, -1.1579e+00],\n",
      "        [ 1.2329e-01, -1.9056e-01,  1.4887e-01,  2.0937e-01],\n",
      "        [-3.2234e-02, -1.2400e-01,  4.5019e-01,  3.9718e-01],\n",
      "        [ 2.3110e-04, -8.2112e-04,  1.5845e-03,  1.5986e-03]])\n"
     ]
    }
   ],
   "source": [
    "# Extract weights of the first layer\n",
    "weights_fc1 = net.fc1.weight.data\n",
    "\n",
    "# Perform SVD on the weights\n",
    "U, S, V = torch.svd(weights_fc1)\n",
    "\n",
    "# Choose the desired rank for the low-rank approximation\n",
    "k = 2  # Example: Choose top 5 singular vectors/values\n",
    "\n",
    "# Form low-rank approximation\n",
    "U_k = U[:, :k]\n",
    "S_k = torch.diag(S[:k])\n",
    "V_k = V[:, :k]\n",
    "low_rank_approximation = torch.mm(U_k, torch.mm(S_k, V_k.t()))\n",
    "\n",
    "# Replace weights of the first layer with the low-rank approximation\n",
    "net.fc1.weight.data = nn.Parameter(low_rank_approximation)\n",
    "\n",
    "print(\"Original weights of the first layer:\")\n",
    "print(weights_fc1)\n",
    "print(\"\\nLow-rank approximation of the first layer:\")\n",
    "print(low_rank_approximation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443576d4-44dc-4c62-8cf3-3297f62f545a",
   "metadata": {},
   "source": [
    "# Find the Optimal Rank to Choose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be52eb2-40ce-4ad2-b3b5-09463c01f4c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T18:46:38.214521900Z",
     "start_time": "2024-04-05T18:46:35.821147900Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "As discussed, various choices of r lead to different levels of approximation, we find $r$ that minimizes the below, where $\\phi$ is any accuracy measure, in particular the AUC,\n",
    "$$\\min_{r\\in{[1, \\frac{m\\times n}{m+n}}]} {r} \\quad \\text{s.t.} \\quad \\phi (y, \\hat{y}) - \\phi (y, \\hat{y'}) < \\delta\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "58366a7b47bca45d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T18:13:11.631226900Z",
     "start_time": "2024-04-05T18:13:11.601550Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from OptimizeRank import OptimizeRank\n",
    "import tensorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22b6d0b278c614b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-05T17:39:43.279024500Z",
     "start_time": "2024-04-05T17:39:43.246819500Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max rank: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\skills-github-pages\\_notebooks\\matrix-factorization\\OptimizeRank.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.tensor = torch.tensor(tensor).float()\n",
      "C:\\Users\\a5144704\\PycharmProjects\\skills-github-pages\\lib\\site-packages\\tensorly\\tucker_tensor.py:425: RuntimeWarning: Given only one int for 'rank' for decomposition a tensor of order 2. Using this rank for all modes.\n",
      "  warnings.warn(message, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "opt_rank = OptimizeRank(X_train_tensor,net,y_train_tensor)\n",
    "optimal_rank, accuracy_diff, space_saved  = opt_rank.optimize_rank_binary_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c1ee1c9-6aeb-41c0-9e59-8dcf5a8b68d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 100.00%\n"
     ]
    }
   ],
   "source": [
    "net.fc1.weight.data = nn.Parameter(low_rank_approximation)\n",
    "train_nn(net) # the accuracy should be the same or close to the benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "533afbab-0492-4365-9e6e-0468fe9acfa5",
   "metadata": {},
   "source": [
    "# Allow the neural network to \"learn\" a lower rank weight structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20193b4b3ffe7e6b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "class NetLite(nn.Module):\n",
    "    def __init__(self, rank):\n",
    "        super(NetLite, self).__init__()\n",
    "        # For the matrix factorization approach we were doing an SVD of W = USV'\n",
    "        # instead of that, we can pass in low rank matrices, u, s, v that mimics that low rank property\n",
    "        # but instead of calculating the values we let back propagation \"learn\" it for us\n",
    "        self.u1 = nn.Linear(4, rank) \n",
    "        self.core1 = nn.Linear(rank, rank)\n",
    "        self.v1 = nn.Linear(rank, 10)\n",
    "        self.fc2 = nn.Linear(10, 3)  # 10 neurons in the hidden layer, 3 output classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # the next 3 are just matrix multiplies without any activation layer\n",
    "        # we want this to mimic a matrix multiplication as closely as possible\n",
    "        x = self.u1(x)\n",
    "        x = self.core1(x)\n",
    "        x = self.v1(x)\n",
    "\n",
    "        # now it is business as usual from here on\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if idx == 0:\n",
    "            return self.fc1\n",
    "        elif idx == 1:\n",
    "            return self.fc2\n",
    "        else:\n",
    "            raise IndexError(\"Index out of range\")\n",
    "            \n",
    "    def return_decomposed_layers(self):\n",
    "        return self.u1, self.core1, self.v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47c6af45-e772-4a7e-95e8-cc0aab40bb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a rank you suspect is a good one, based on the optimal rank using W directly\n",
    "netLite = NetLite(rank=optimal_rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d02b18eb-2a57-4880-9c5f-bb49ce8d6b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original FLOPS : 8.4K, #params : 83.0\n",
      "Lite FLOPS : 5.4K, #params : 60.0\n"
     ]
    }
   ],
   "source": [
    "from flopth import flopth\n",
    "# Using a random package off the internet to get FLOPs, RESTART KERNEL IF YOU SEE KeyError: \"attribute 'flops' already exists\"\n",
    "dummy_inputs = torch.rand(X_train.shape)\n",
    "flops, params = flopth(net, inputs=(dummy_inputs,))\n",
    "print(f\"Original FLOPS : {flops}, #params : {params}\")\n",
    "flops, params = flopth(netLite, inputs=(dummy_inputs,))\n",
    "print(f\"Lite FLOPS : {flops}, #params : {params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e434d0e3-2052-46fd-a871-c3e3a363ce7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned Low Rank Weights of the First Layer\n",
      "[[ 0.45  0.49 -0.14  0.54]\n",
      " [ 0.68  0.74 -0.21  0.82]\n",
      " [-0.57 -0.61  0.17 -0.68]\n",
      " [ 0.67  0.73 -0.21  0.81]\n",
      " [ 0.14  0.16 -0.04  0.17]\n",
      " [ 0.57  0.62 -0.17  0.68]\n",
      " [ 0.1   0.11 -0.03  0.13]\n",
      " [ 0.37  0.4  -0.11  0.45]\n",
      " [-0.11 -0.12  0.03 -0.13]\n",
      " [ 0.59  0.65 -0.18  0.71]]\n",
      "Original Weights of the First Layer\n",
      "[[-0.08 -0.51  1.73  1.55]\n",
      " [-0.05 -0.19  0.71  0.62]\n",
      " [ 0.18 -0.61  0.99  1.03]\n",
      " [ 0.15  0.21 -1.06 -0.89]\n",
      " [ 0.24  0.17 -1.24 -1.  ]\n",
      " [-0.03  0.09 -0.17 -0.17]\n",
      " [-0.26  0.68 -1.11 -1.17]\n",
      " [ 0.12 -0.2   0.15  0.21]\n",
      " [-0.03 -0.12  0.46  0.4 ]\n",
      " [ 0.   -0.    0.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "# W_dash is what the neural network proposes as a rough equivalent of W, they can be very different as shown below.\n",
    "# This is because the neural network learns the best low rank matrix triplet that minimizes the loss, not the one that approximates W as closely as possible. \n",
    "\n",
    "u1, core1, v1 = netLite.return_decomposed_layers()\n",
    "W_dash = torch.mm(torch.mm(u1.weight.T, core1.weight), v1.weight.T)\n",
    "print(\"Learned Low Rank Weights of the First Layer\")\n",
    "print(np.round(W_dash.T.detach().numpy()*10,2))\n",
    "W = net.get_first_layer().weight\n",
    "print(\"Original Weights of the First Layer\")\n",
    "print(np.round(W.detach().numpy(),2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
